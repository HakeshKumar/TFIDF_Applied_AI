{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 248,
   "metadata": {},
   "outputs": [],
   "source": [
    "string=['my name is hakesh kumar',\n",
    "         'i am working in moengage company',\n",
    "        'my role in the company is solution engineer',\n",
    "        'i am very much interested in machine learning']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 311,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.2876820724517808\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "s=1+np.log((4)/(3))\n",
    "print(s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 250,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['my name is hakesh kumar',\n",
       " 'i am working in moengage company',\n",
       " 'my role in the company is solution engineer',\n",
       " 'i am very much interested in machine learning']"
      ]
     },
     "execution_count": 250,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 272,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm \n",
    "from sklearn.preprocessing import normalize\n",
    "def fit(dataset):    \n",
    "    unique_words = set()\n",
    "    if isinstance(dataset, (list)):\n",
    "        for row in dataset: \n",
    "            for word in row.split(\" \"): \n",
    "                if len(word) < 2:\n",
    "                    continue\n",
    "                unique_words.add(word)\n",
    "        unique_words = sorted(list(unique_words))\n",
    "        vocab = {j:i for i,j in enumerate(unique_words)}\n",
    "        return vocab\n",
    "    else:\n",
    "        print(\"you need to pass list of sentance\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 274,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'am': 0, 'company': 1, 'engineer': 2, 'hakesh': 3, 'in': 4, 'interested': 5, 'is': 6, 'kumar': 7, 'learning': 8, 'machine': 9, 'moengage': 10, 'much': 11, 'my': 12, 'name': 13, 'role': 14, 'solution': 15, 'the': 16, 'very': 17, 'working': 18}\n"
     ]
    }
   ],
   "source": [
    "vocab=fit(string)\n",
    "print(vocab)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Comparing FIT and SKLearn  alphabetical order "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 254,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
       "                dtype=<class 'numpy.float64'>, encoding='utf-8',\n",
       "                input='content', lowercase=True, max_df=1.0, max_features=None,\n",
       "                min_df=1, ngram_range=(1, 1), norm='l2', preprocessor=None,\n",
       "                smooth_idf=True, stop_words=None, strip_accents=None,\n",
       "                sublinear_tf=False, token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b',\n",
       "                tokenizer=None, use_idf=True, vocabulary=None)"
      ]
     },
     "execution_count": 254,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "vectorizer = TfidfVectorizer()\n",
    "vectorizer.fit(string)\n",
    "#skl_output = vectorizer.transform()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 276,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['am', 'company', 'engineer', 'hakesh', 'in', 'interested', 'is', 'kumar', 'learning', 'machine', 'moengage', 'much', 'my', 'name', 'role', 'solution', 'the', 'very', 'working']\n",
      "['am', 'company', 'engineer', 'hakesh', 'in', 'interested', 'is', 'kumar', 'learning', 'machine', 'moengage', 'much', 'my', 'name', 'role', 'solution', 'the', 'very', 'working']\n"
     ]
    }
   ],
   "source": [
    "print(vectorizer.get_feature_names())\n",
    "print(list(vocab))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 256,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 301,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['my name is hakesh kumar', 'i am working in moengage company', 'my role in the company is solution engineer', 'i am very much interested in machine learning']\n"
     ]
    }
   ],
   "source": [
    "A=list(string)\n",
    "print(A)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 307,
   "metadata": {},
   "outputs": [],
   "source": [
    "test= 'my name is hakesh kumar i am working in moengage company my role in the company is solution engineer i am very much interested in machine learning'  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 313,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'dict' object has no attribute 'count'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-313-4450ab60e6e5>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mvocab\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcount\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m: 'dict' object has no attribute 'count'"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Transform "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 259,
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://stackoverflow.com/questions/9919604/efficiently-calculate-word-frequency-in-a-string\n",
    "# https://docs.scipy.org/doc/scipy-0.19.0/reference/generated/scipy.sparse.csr_matrix.html\n",
    "# note that we are we need to send the preprocessing text here, we have not inlcuded the processing\n",
    "from collections import Counter\n",
    "from scipy.sparse import csr_matrix\n",
    "def transform(dataset,vocab):\n",
    "    rows = []\n",
    "    columns = []\n",
    "    values = []\n",
    "    if isinstance(dataset, (list,)):\n",
    "        for idx, row in enumerate(tqdm(dataset)): # for each document in the dataset\n",
    "            # it will return a dict type object where key is the word and values is its frequency, {word:frequency}\n",
    "            word_freq = dict(Counter(row.split()))\n",
    "            # for every unique word in the document\n",
    "            for word, freq in word_freq.items():  # for each unique word in the review.                \n",
    "                if len(word) < 2:\n",
    "                    continue\n",
    "                # we will check if its there in the vocabulary that we build in fit() function\n",
    "                # dict.get() function will return the values, if the key doesn't exits it will return -1\n",
    "                col_index = vocab.get(word, -1) # retreving the dimension number of a word\n",
    "                # if the word exists\n",
    "                if col_index !=-1:\n",
    "                    # we are storing the index of the document\n",
    "                    rows.append(idx)\n",
    "                    # we are storing the dimensions of the word\n",
    "                    columns.append(col_index)\n",
    "                    # we are storing the frequency of the word\n",
    "                    values.append(freq)\n",
    "        return csr_matrix((values, (rows,columns)), shape=(len(dataset),len(vocab)))\n",
    "    else:\n",
    "        print(\"you need to pass list of strings\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 260,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4/4 [00:00<00:00, 2162.29it/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<4x19 sparse matrix of type '<class 'numpy.int64'>'\n",
       "\twith 25 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 260,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "transform(string,vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 261,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4/4 [00:00<00:00, 5355.00it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['am', 'company', 'engineer', 'hakesh', 'in', 'interested', 'is', 'kumar', 'learning', 'machine', 'moengage', 'much', 'my', 'name', 'role', 'solution', 'the', 'very', 'working']\n",
      "[[0 0 0 1 0 0 1 1 0 0 0 0 1 1 0 0 0 0 0]\n",
      " [1 1 0 0 1 0 0 0 0 0 1 0 0 0 0 0 0 0 1]\n",
      " [0 1 1 0 1 0 1 0 0 0 0 0 1 0 1 1 1 0 0]\n",
      " [1 0 0 0 1 1 0 0 1 1 0 1 0 0 0 0 0 1 0]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "print(list(vocab.keys()))\n",
    "print(transform(string, vocab).toarray())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 262,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0 0 0 1 0 0 1 1 0 0 0 0 1 1 0 0 0 0 0]\n",
      " [1 1 0 0 1 0 0 0 0 0 1 0 0 0 0 0 0 0 1]\n",
      " [0 1 1 0 1 0 1 0 0 0 0 0 1 0 1 1 1 0 0]\n",
      " [1 0 0 0 1 1 0 0 1 1 0 1 0 0 0 0 0 1 0]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "from sklearn import preprocessing\n",
    "vec = CountVectorizer(analyzer='word')\n",
    "\n",
    "vec.fit(string)\n",
    "feature_matrix_2 = vec.transform(string)\n",
    "print(feature_matrix_2.toarray())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 263,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4/4 [00:00<00:00, 3445.01it/s]\n"
     ]
    }
   ],
   "source": [
    "a=transform(string, vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 264,
   "metadata": {},
   "outputs": [],
   "source": [
    "b=normalize(a, norm='l2', )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 265,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.        0.        0.        0.4472136 0.        0.        0.4472136\n",
      "  0.4472136 0.        0.        0.        0.        0.4472136 0.4472136\n",
      "  0.        0.        0.        0.        0.       ]]\n"
     ]
    }
   ],
   "source": [
    "print(b[0].toarray())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 266,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf_idf_vect=TfidfVectorizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 267,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
       "                dtype=<class 'numpy.float64'>, encoding='utf-8',\n",
       "                input='content', lowercase=True, max_df=1.0, max_features=None,\n",
       "                min_df=1, ngram_range=(1, 1), norm='l2', preprocessor=None,\n",
       "                smooth_idf=True, stop_words=None, strip_accents=None,\n",
       "                sublinear_tf=False, token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b',\n",
       "                tokenizer=None, use_idf=True, vocabulary=None)"
      ]
     },
     "execution_count": 267,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf_idf_vect.fit(string)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 268,
   "metadata": {},
   "outputs": [],
   "source": [
    "out=tf_idf_vect.transform(string)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 269,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1.51082562, 1.51082562, 1.91629073, 1.91629073, 1.22314355,\n",
       "       1.91629073, 1.51082562, 1.91629073, 1.91629073, 1.91629073,\n",
       "       1.91629073, 1.91629073, 1.51082562, 1.91629073, 1.91629073,\n",
       "       1.91629073, 1.91629073, 1.91629073, 1.91629073])"
      ]
     },
     "execution_count": 269,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf_idf_vect.idf_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 270,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4, 19)"
      ]
     },
     "execution_count": 270,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "out.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 271,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.         0.         0.         0.48546061 0.         0.\n",
      "  0.38274272 0.48546061 0.         0.         0.         0.\n",
      "  0.38274272 0.48546061 0.         0.         0.         0.\n",
      "  0.        ]]\n"
     ]
    }
   ],
   "source": [
    "print(out[0].toarray())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
